{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "processing.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
<<<<<<< HEAD
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NeelayS/ppe-detection/blob/main/processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NeelayS/ppe-detection/blob/main/processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yW8xlOf2sckM",
        "outputId": "2c4d694e-f529-469c-f009-4a252c26a848"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/projects/ppe\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/projects/ppe/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iW-rXoYAYcFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, io\n",
        "from os.path import join\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "mbjV4MLr4_S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "rx7aV7ZvYg1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PictorPPEDataset(Dataset):\n",
        "    def __init__(self, img_dir, annotations_list):\n",
        "        super().__init__()\n",
        "\n",
        "        self.img_dir = img_dir\n",
        "\n",
        "        with open(annotations_list, \"rb\") as f:\n",
        "            self.annotations = sorted(f.readlines())\n",
        "        f.close()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        annotation = str(self.annotations[idx])[2:-5].split(\"\\\\t\")\n",
        "\n",
        "        img_name = annotation[0]\n",
        "        img = io.read_image(join(self.img_dir, img_name))\n",
        "\n",
        "        cropped_detections = []\n",
        "        labels = []\n",
        "\n",
        "        for det_annotation in annotation[1:]:\n",
        "\n",
        "            label = int(det_annotation[-1])\n",
        "            if label==2 or label==3:\n",
        "              label=1\n",
        "            labels.append(label)\n",
        "\n",
        "            x1, y1, x2, y2 = list(map(lambda x: int(x), det_annotation[:-2].split(\",\")))\n",
        "            cropped_detection = img[:, y1:y2, x1:x2].float()\n",
        "            cropped_detections.append(cropped_detection)\n",
        "\n",
        "        return cropped_detections, labels\n"
      ],
      "metadata": {
        "id": "oYH7JSfr5Fyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = PictorPPEDataset(\"./Images\", \"Labels/pictor_ppe_crowdsourced_approach-02_train.txt\")"
      ],
      "metadata": {
        "id": "JKsf3Gbx9WId"
      },
      "execution_count": null,
      "outputs": []
>>>>>>> 4110f4f6fb28c0de2385ce5817827727ccc9f01b
    },
    "id": "yW8xlOf2sckM",
    "outputId": "d23a35d6-d4bf-4e57-ef3a-148aeae76625"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/drive/MyDrive/projects/ppe\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/projects/ppe/"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "id": "iW-rXoYAYcFe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, io\n",
    "from os.path import join\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "mbjV4MLr4_S0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "id": "rx7aV7ZvYg1h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class PictorPPEDataset(Dataset):\n",
    "    def __init__(self, img_dir, annotations_list):\n",
    "        super().__init__()\n",
    "\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "        with open(annotations_list, \"rb\") as f:\n",
    "            self.annotations = sorted(f.readlines())\n",
    "        f.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        annotation = str(self.annotations[idx])[2:-5].split(\"\\\\t\")\n",
    "\n",
    "        img_name = annotation[0]\n",
    "        img = io.read_image(join(self.img_dir, img_name))\n",
    "\n",
    "        cropped_detections = []\n",
    "        labels = []\n",
    "\n",
    "        for det_annotation in annotation[1:]:\n",
    "\n",
    "            label = int(det_annotation[-1])\n",
    "            if label == 2 or label == 3:\n",
    "                label = 1\n",
    "            labels.append(label)\n",
    "\n",
    "            x1, y1, x2, y2 = list(map(lambda x: int(x), det_annotation[:-2].split(\",\")))\n",
    "            cropped_detection = img[:, y1:y2, x1:x2].float()\n",
    "            cropped_detections.append(cropped_detection)\n",
    "\n",
    "        return cropped_detections, labels"
   ],
   "metadata": {
    "id": "oYH7JSfr5Fyg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = PictorPPEDataset(\n",
    "    \"./Images\", \"Labels/pictor_ppe_crowdsourced_approach-02_train.txt\"\n",
    ")"
   ],
   "metadata": {
    "id": "JKsf3Gbx9WId"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1)"
   ],
   "metadata": {
    "id": "lgb39SV_9jMG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sample = next(iter(dataloader))\n",
    "print(type(sample))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sSxxCqiAfNdU",
    "outputId": "43ff64dc-4a02-48aa-ccb6-39a5e9dea079"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "l_0 = 0\n",
    "l_1 = 0\n",
    "l_2 = 0\n",
    "l_3 = 0\n",
    "\n",
    "for _, labels in dataloader:\n",
    "    for label in labels:\n",
    "        if label.item() == 0:\n",
    "            l_0 += 1\n",
    "        elif label.item() == 1:\n",
    "            l_1 += 1\n",
    "        elif label.item() == 2:\n",
    "            l_2 += 1\n",
    "        else:\n",
    "            l_3 += 1\n",
    "\n",
    "print(l_0, l_1, l_2, l_3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOiAfNxzSoZc",
    "outputId": "04e6ee56-94ce-44d2-eea3-3c3aa8ed19e2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "577 1069 0 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "sample[1][0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Hnr6qW69_FJ",
    "outputId": "2e681dc5-3aa7-4754-8e2c-773f502e3763"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"Labels/pictor_ppe_crowdsourced_approach-02_train.txt\", \"rb\") as f:\n",
    "    annotations = sorted(f.readlines())"
   ],
   "metadata": {
    "id": "frbnVUJs6E3x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "type(annotations)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ZiQUVtr6QUz",
    "outputId": "6d7917e6-55c7-460d-e60a-26e565ef116a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "str(annotations[1])[2:-5].split(\"\\\\t\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwY0_wUA6R13",
    "outputId": "2a953daf-913b-400e-ef2e-a9dc05477d80"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['image_from_china(10).jpg',\n",
       " '143,165,202,277,0',\n",
       " '319,157,328,192,0',\n",
       " '343,158,355,188,0',\n",
       " '328,157,339,191,0']"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "str(annotations[1])[2:-5].split(\"\\\\t\")[1][:-2].split(\",\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_B7ILQ4o6Tvv",
    "outputId": "fc9f3c92-290d-4077-b780-69e68012451b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['143', '165', '202', '277']"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "crop = sample[0][0]\n",
    "crop.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MGrC7wS_aHVI",
    "outputId": "37b2aa05-cdf6-4062-c78e-7fb096cb0486"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 145, 48])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "id": "nb2C6cPBaNP7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "crop = crop.squeeze(0).permute(1, 2, 0).numpy()\n",
    "plt.imshow(crop)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "Uo9gjvSbaRrB",
    "outputId": "7e817984-2ae4-422c-dcb2-19b3d89ef9c7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1e61105c50>"
      ]
     },
     "metadata": {},
     "execution_count": 60
    },
    {
<<<<<<< HEAD
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
=======
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "4Tj6izByb5bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorchyolo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lbzXVTFEcA6Q",
        "outputId": "a0edac10-6bec-4d98-85a7-2a24cb9f9b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorchyolo\n",
            "  Downloading PyTorchYolo-1.6.2-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▊                        | 10 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 20 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 40 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 695 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.55.1 in /usr/local/lib/python3.7/dist-packages (from pytorchyolo) (4.63.0)\n",
            "Requirement already satisfied: torchsummary<2.0.0,>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from pytorchyolo) (1.5.1)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorchyolo) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from pytorchyolo) (1.21.5)\n",
            "Collecting matplotlib<4.0.0,>=3.3.3\n",
            "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 8.4 MB/s \n",
            "\u001b[?25hCollecting Pillow<9.0.0,>=8.1.0\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 31.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from pytorchyolo) (0.11.1+cu111)\n",
            "Collecting imgaug<0.5.0,>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting terminaltables<4.0.0,>=3.1.0\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tensorboard<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from pytorchyolo) (2.8.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug<0.5.0,>=0.4.0->pytorchyolo) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.5.0,>=0.4.0->pytorchyolo) (0.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.5.0,>=0.4.0->pytorchyolo) (1.15.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug<0.5.0,>=0.4.0->pytorchyolo) (1.8.1.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug<0.5.0,>=0.4.0->pytorchyolo) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug<0.5.0,>=0.4.0->pytorchyolo) (4.1.2.30)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.3.3->pytorchyolo) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.3.3->pytorchyolo) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.3.3->pytorchyolo) (1.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.3.3->pytorchyolo) (0.11.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.31.2-py3-none-any.whl (899 kB)\n",
            "\u001b[K     |████████████████████████████████| 899 kB 20.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.3.3->pytorchyolo) (3.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<4.0.0,>=3.3.3->pytorchyolo) (3.10.0.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug<0.5.0,>=0.4.0->pytorchyolo) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug<0.5.0,>=0.4.0->pytorchyolo) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug<0.5.0,>=0.4.0->pytorchyolo) (2.6.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (1.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3.0.0,>=2.4.0->pytorchyolo) (1.44.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3.0.0,>=2.4.0->pytorchyolo) (3.2.0)\n",
            "Installing collected packages: Pillow, fonttools, matplotlib, terminaltables, imgaug, pytorchyolo\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Pillow-8.4.0 fonttools-4.31.2 imgaug-0.4.0 matplotlib-3.5.1 pytorchyolo-1.6.2 terminaltables-3.1.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from pytorchyolo import detect, models as yolo_models\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import io, models\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, features_dim, layers_config=[1024, 512]):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features_dim = features_dim\n",
        "\n",
        "        layers_config = [features_dim] + list(layers_config)\n",
        "\n",
        "        self.head = nn.ModuleList()\n",
        "        for i in range(0, len(layers_config) - 1):\n",
        "            self.head.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Linear(layers_config[i], layers_config[i + 1]),\n",
        "                    nn.ReLU(),\n",
        "                ),\n",
        "            )\n",
        "        self.head.append(nn.Linear(layers_config[-1], 2))\n",
        "        self.head = nn.Sequential(*self.head)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return self.head(x)\n",
        "\n",
        "\n",
        "class YoloV3DetectionModel:\n",
        "    def __init__(self, config_path, weights_path, threshold=0.5):\n",
        "\n",
        "        self.threshold = threshold\n",
        "\n",
        "        self.model = yolo_models.load_model(config_path, weights_path)\n",
        "\n",
        "    def _filter_detections(self, detections):\n",
        "\n",
        "        filtered_detections = []\n",
        "\n",
        "        for detection in detections:\n",
        "\n",
        "            if (\n",
        "                detection[-2] > self.threshold and int(detection[-1]) == 0\n",
        "            ):  # 0 = person class\n",
        "                filtered_detections.append(list(map(lambda x: int(x), detection[:-2])))\n",
        "\n",
        "        return filtered_detections\n",
        "\n",
        "    def __call__(self, img_path):\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        detections = detect.detect_image(self.model, img)\n",
        "        detections = self._filter_detections(detections)\n",
        "\n",
        "        print(f\"Detected {len(detections)} persons\")\n",
        "\n",
        "        img = io.read_image(img_path)\n",
        "\n",
        "        cropped_detections = []\n",
        "        for detection in detections:\n",
        "            cropped_detections.append(\n",
        "                img[:, detection[1] : detection[3], detection[0] : detection[2]]\n",
        "                .unsqueeze(0)\n",
        "                .float()\n",
        "            )\n",
        "\n",
        "        return cropped_detections\n",
        "\n",
        "\n",
        "class ClassificationModel(nn.Module):\n",
        "    def __init__(\n",
        "        self, reshape_size, features_dim, layers_config, n_heads, backbone=None\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.reshape_size = reshape_size\n",
        "\n",
        "        if backbone is None:\n",
        "            self.backbone = models.vgg19(pretrained=True).features\n",
        "        else:\n",
        "            self.backbone = backbone\n",
        "\n",
        "        self.heads = nn.ModuleList()\n",
        "        for _ in range(n_heads):\n",
        "            self.heads.append(\n",
        "                ClassificationHead(\n",
        "                    features_dim=features_dim, layers_config=layers_config\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, detections):\n",
        "\n",
        "        outs = []\n",
        "\n",
        "        for detection in detections:\n",
        "\n",
        "            detection = F.interpolate(\n",
        "                detection, self.reshape_size, mode=\"bilinear\", align_corners=True\n",
        "            )\n",
        "            features = self.backbone(detection)\n",
        "\n",
        "            instance_outs = []\n",
        "\n",
        "            for head in self.heads:\n",
        "                out = head(features)\n",
        "                instance_outs.append(out)\n",
        "\n",
        "            outs.append(instance_outs)\n",
        "\n",
        "        return outs\n",
        "\n",
        "\n",
        "class CompleteModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        detection_threshold,\n",
        "        detection_config,\n",
        "        detection_weights,\n",
        "        detection_reshape_size,\n",
        "        classification_features_dim,\n",
        "        classification_layers_config,\n",
        "        classification_n_heads,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.detection_model = YoloV3DetectionModel(\n",
        "            config_path=detection_config,\n",
        "            weights_path=detection_weights,\n",
        "            threshold=detection_threshold,\n",
        "        )\n",
        "        self.classification_model = ClassificationModel(\n",
        "            reshape_size=detection_reshape_size,\n",
        "            features_dim=classification_features_dim,\n",
        "            layers_config=classification_layers_config,\n",
        "            n_heads=classification_n_heads,\n",
        "        )\n",
        "\n",
        "    def forward(self, img_path):\n",
        "\n",
        "        detections = self.detection_model(img_path)\n",
        "        img_outs = self.classification_model(detections)\n",
        "\n",
        "        return img_outs\n",
        "\n",
        "\n",
        "# Map outs for a detection uniquely to the detection\n",
        "# Pre-process images\n",
        "# Detection model\n",
        "# Load pre-trained weights"
>>>>>>> 4110f4f6fb28c0de2385ce5817827727ccc9f01b
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Definition"
   ],
   "metadata": {
    "id": "4Tj6izByb5bS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pytorchyolo"
   ],
   "metadata": {
    "id": "lbzXVTFEcA6Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from pytorchyolo import detect, models as yolo_models\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import io, models\n",
    "\n",
    "\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, features_dim, layers_config=[1024, 512]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features_dim = features_dim\n",
    "\n",
    "        layers_config = [features_dim] + list(layers_config)\n",
    "\n",
    "        self.head = nn.ModuleList()\n",
    "        for i in range(0, len(layers_config) - 1):\n",
    "            self.head.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(layers_config[i], layers_config[i + 1]),\n",
    "                    nn.ReLU(),\n",
    "                ),\n",
    "            )\n",
    "        self.head.append(nn.Linear(layers_config[-1], 2))\n",
    "        self.head = nn.Sequential(*self.head)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        return self.head(x)\n",
    "\n",
    "\n",
    "class YoloV3DetectionModel:\n",
    "    def __init__(self, config_path, weights_path, threshold=0.5):\n",
    "\n",
    "        self.threshold = threshold\n",
    "\n",
    "        self.model = yolo_models.load_model(config_path, weights_path)\n",
    "\n",
    "    def _filter_detections(self, detections):\n",
    "\n",
    "        filtered_detections = []\n",
    "\n",
    "        for detection in detections:\n",
    "\n",
    "            if (\n",
    "                detection[-2] > self.threshold and int(detection[-1]) == 0\n",
    "            ):  # 0 = person class\n",
    "                filtered_detections.append(list(map(lambda x: int(x), detection[:-2])))\n",
    "\n",
    "        return filtered_detections\n",
    "\n",
    "    def __call__(self, img_path):\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        detections = detect.detect_image(self.model, img)\n",
    "        detections = self._filter_detections(detections)\n",
    "\n",
    "        print(f\"Detected {len(detections)} persons\")\n",
    "\n",
    "        img = io.read_image(img_path)\n",
    "\n",
    "        cropped_detections = []\n",
    "        for detection in detections:\n",
    "            cropped_detections.append(\n",
    "                img[:, detection[1] : detection[3], detection[0] : detection[2]]\n",
    "                .unsqueeze(0)\n",
    "                .float()\n",
    "            )\n",
    "\n",
    "        return cropped_detections\n",
    "\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(\n",
    "        self, reshape_size, features_dim, layers_config, n_heads, backbone=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.reshape_size = reshape_size\n",
    "\n",
    "        if backbone is None:\n",
    "            self.backbone = models.vgg19(pretrained=False).features\n",
    "        else:\n",
    "            self.backbone = backbone\n",
    "\n",
    "        self.heads = nn.ModuleList()\n",
    "        for _ in range(n_heads):\n",
    "            self.heads.append(\n",
    "                ClassificationHead(\n",
    "                    features_dim=features_dim, layers_config=layers_config\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, detections):\n",
    "\n",
    "        outs = []\n",
    "\n",
    "        for detection in detections:\n",
    "\n",
    "            detection = F.interpolate(\n",
    "                detection, self.reshape_size, mode=\"bilinear\", align_corners=True\n",
    "            )\n",
    "            features = self.backbone(detection)\n",
    "\n",
    "            instance_outs = []\n",
    "\n",
    "            for head in self.heads:\n",
    "                out = head(features)\n",
    "                instance_outs.append(out)\n",
    "\n",
    "            outs.append(instance_outs)\n",
    "\n",
    "        return outs\n",
    "\n",
    "\n",
    "class CompleteModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        detection_threshold,\n",
    "        detection_config,\n",
    "        detection_weights,\n",
    "        detection_reshape_size,\n",
    "        classification_features_dim,\n",
    "        classification_layers_config,\n",
    "        classification_n_heads,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.detection_model = YoloV3DetectionModel(\n",
    "            config_path=detection_config,\n",
    "            weights_path=detection_weights,\n",
    "            threshold=detection_threshold,\n",
    "        )\n",
    "        self.classification_model = ClassificationModel(\n",
    "            reshape_size=detection_reshape_size,\n",
    "            features_dim=classification_features_dim,\n",
    "            layers_config=classification_layers_config,\n",
    "            n_heads=classification_n_heads,\n",
    "        )\n",
    "\n",
    "    def forward(self, img_path):\n",
    "\n",
    "        detections = self.detection_model(img_path)\n",
    "        img_outs = self.classification_model(detections)\n",
    "\n",
    "        return img_outs\n",
    "\n",
    "\n",
    "# Map outs for a detection uniquely to the detection\n",
    "# Pre-process images\n",
    "# Detection model\n",
    "# Load pre-trained weights"
   ],
   "metadata": {
    "id": "oehk8ZyKb9yA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = ClassificationModel((96, 32), 1536, (512, 128), 1)"
   ],
   "metadata": {
    "id": "tXDn_MFac4K8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "out = model(sample[0])\n",
    "type(out)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lWOUmpnMebqu",
    "outputId": "19311202-3413-4ccb-b221-4959e55e60eb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "out = [o[0] for o in out]\n",
    "out = torch.cat(out)\n",
    "out.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Et13qrN3fg-A",
    "outputId": "7cbe591e-0c11-4a08-a4e9-547d1a12d2b1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "out, sample[1]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3t1Nr9dkgpNe",
    "outputId": "8d1f0f6e-ad06-4418-ad55-762f6d991e94"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[ 0.1794, -0.3224],\n",
       "         [ 0.1898, -0.2405],\n",
       "         [ 0.1642, -0.1922]], grad_fn=<CatBackward0>),\n",
       " [tensor([1]), tensor([1]), tensor([1])])"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "label = torch.LongTensor(sample[1])\n",
    "label"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVemQDCRg8sA",
    "outputId": "fee42d80-30bc-4e0e-effb-b52a142aed8c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 1, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "loss_fn(out, sample[1])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5h9zwIj2hopc",
    "outputId": "2e660d27-86e3-42ee-b4b9-0bd73f4f96f8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.9312, grad_fn=<NllLossBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "id": "JoOtFRPmYjOy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def loss_fn(preds, labels):\n",
    "\n",
    "    preds = [pred[0] for pred in preds]\n",
    "    preds = torch.cat(preds)\n",
    "    # labels = torch.LongTensor(labels)\n",
    "\n",
    "    loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "id": "kxUk2BsxYnXi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_classifier(model, dataloader, optimizer, epochs, device, save_dir):\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    iter_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i, (data, labels) in enumerate(dataloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            data = [d.to(device) for d in data]\n",
    "            labels = torch.LongTensor(labels).to(device)\n",
    "\n",
    "            # data, labels = data.to(device), labels.to(device)\n",
    "            preds = model(data)\n",
    "\n",
    "            loss = loss_fn(preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 50 == 0:\n",
    "                print(f\"Iteration {(epoch*len(dataloader)) + i}: Loss = {loss.item()}\")\n",
    "                iter_losses.append(loss.item())\n",
    "\n",
    "            if (i + 1) % 500 == 0:\n",
    "                torch.save(\n",
    "                    model,\n",
    "                    join(\n",
    "                        save_dir,\n",
    "                        \"iter\" + str((epoch * len(dataloader)) + i) + \"_model.pth\",\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "    plt.plot(iter_losses)"
   ],
   "metadata": {
    "id": "YMzY_KH96bPf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = PictorPPEDataset(\n",
    "    \"data/Images\", \"data/Labels/pictor_ppe_crowdsourced_approach-02_train.txt\"\n",
    ")\n",
    "trainloader = DataLoader(train_dataset, batch_size=1)"
   ],
   "metadata": {
    "id": "ggvEiW-DmJYC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = ClassificationModel((96, 32), 1536, (512, 128), 1)\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJGfR5RTk8tf",
    "outputId": "06a17c53-ecfa-4ff8-b873-360da69c780f"
   },
   "execution_count": null,
   "outputs": [
    {
<<<<<<< HEAD
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "id": "jbbp3vgCk_Mn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 100\n",
    "\n",
    "train_classifier(model, trainloader, optimizer, epochs, device, \"model_weights\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
=======
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "JoOtFRPmYjOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(preds, labels):\n",
        "\n",
        "  preds = [pred[0] for pred in preds]\n",
        "  preds = torch.cat(preds)\n",
        "  # labels = torch.LongTensor(labels)\n",
        "\n",
        "  loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "kxUk2BsxYnXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(model, dataloader, optimizer, epochs, device, save_dir):\n",
        "\n",
        "  model = model.to(device)\n",
        "  model.train()\n",
        "\n",
        "  iter_losses = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for i, (data, labels) in enumerate(dataloader):\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      data = [d.to(device) for d in data]\n",
        "      labels = torch.LongTensor(labels).to(device)\n",
        "\n",
        "     # data, labels = data.to(device), labels.to(device)\n",
        "      preds = model(data)\n",
        "\n",
        "      loss = loss_fn(preds, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (i+1)%200==0:\n",
        "        print(f\"Iteration {(epoch*len(dataloader)) + i}: Loss = {loss.item()}\")\n",
        "        iter_losses.append(loss.item())\n",
        "\n",
        "      if i%5000==0:\n",
        "        torch.save(model.state_dict(), join(save_dir, \"iter\" + str((epoch*len(dataloader)) + i) + \"_model.pth\"))\n",
        "\n",
        "  plt.plot(iter_losses)"
      ],
      "metadata": {
        "id": "YMzY_KH96bPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PictorPPEDataset(\"data/Images\", \"data/Labels/pictor_ppe_crowdsourced_approach-02_train.txt\")\n",
        "trainloader = DataLoader(train_dataset, batch_size=1)"
      ],
      "metadata": {
        "id": "ggvEiW-DmJYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = ClassificationModel((96, 32), 1536, (512, 128), 1)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJGfR5RTk8tf",
        "outputId": "975dfed1-428a-43bc-ad87-5721e6065dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
>>>>>>> 4110f4f6fb28c0de2385ce5817827727ccc9f01b
    },
    "id": "p9Z_1EFllBgV",
    "outputId": "c0053185-2a4e-4917-f2a0-2b5d8d81f050"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 49: Loss = 0.6956713795661926\n",
      "Iteration 99: Loss = 0.601978600025177\n",
      "Iteration 149: Loss = 0.6381157636642456\n",
      "Iteration 199: Loss = 0.7096593976020813\n",
      "Iteration 249: Loss = 0.6294102668762207\n",
      "Iteration 299: Loss = 0.7049644589424133\n",
      "Iteration 349: Loss = 0.6709908246994019\n",
      "Iteration 399: Loss = 0.6072259545326233\n",
      "Iteration 449: Loss = 0.5837963819503784\n",
      "Iteration 499: Loss = 0.5045965313911438\n",
      "Iteration 551: Loss = 0.9168224334716797\n",
      "Iteration 601: Loss = 0.5909722447395325\n",
      "Iteration 651: Loss = 0.5473790168762207\n",
      "Iteration 701: Loss = 0.7367261052131653\n",
      "Iteration 751: Loss = 0.564365029335022\n",
      "Iteration 801: Loss = 0.7606641054153442\n",
      "Iteration 851: Loss = 0.6226842999458313\n",
      "Iteration 901: Loss = 0.5932342410087585\n",
      "Iteration 951: Loss = 0.552768886089325\n",
      "Iteration 1001: Loss = 0.5260699391365051\n",
      "Iteration 1053: Loss = 1.0072098970413208\n",
      "Iteration 1103: Loss = 0.5737525224685669\n",
      "Iteration 1153: Loss = 0.5167238712310791\n",
      "Iteration 1203: Loss = 0.7541134357452393\n",
      "Iteration 1253: Loss = 0.5555214881896973\n",
      "Iteration 1303: Loss = 0.7642074823379517\n",
      "Iteration 1353: Loss = 0.6055101752281189\n",
      "Iteration 1403: Loss = 0.5862954258918762\n",
      "Iteration 1453: Loss = 0.544101893901825\n",
      "Iteration 1503: Loss = 0.5218348503112793\n",
      "Iteration 1555: Loss = 1.014995813369751\n",
      "Iteration 1605: Loss = 0.5731473565101624\n",
      "Iteration 1655: Loss = 0.5126025080680847\n",
      "Iteration 1705: Loss = 0.7536785006523132\n",
      "Iteration 1755: Loss = 0.5585476160049438\n",
      "Iteration 1805: Loss = 0.7461457252502441\n",
      "Iteration 1855: Loss = 0.5959495306015015\n",
      "Iteration 1905: Loss = 0.581657350063324\n",
      "Iteration 1955: Loss = 0.5357944369316101\n",
      "Iteration 2005: Loss = 0.513006865978241\n",
      "Iteration 2057: Loss = 1.01886785030365\n",
      "Iteration 2107: Loss = 0.5666509866714478\n",
      "Iteration 2157: Loss = 0.5304651260375977\n",
      "Iteration 2207: Loss = 0.7512593865394592\n",
      "Iteration 2257: Loss = 0.5035377740859985\n",
      "Iteration 2307: Loss = 0.7662888765335083\n",
      "Iteration 2357: Loss = 0.6158897280693054\n",
      "Iteration 2407: Loss = 0.5897445678710938\n",
      "Iteration 2457: Loss = 0.5430766940116882\n",
      "Iteration 2507: Loss = 0.5125505924224854\n",
      "Iteration 2559: Loss = 0.9936436414718628\n",
      "Iteration 2609: Loss = 0.48793825507164\n",
      "Iteration 2659: Loss = 0.5848456621170044\n",
      "Iteration 2709: Loss = 0.7199813723564148\n",
      "Iteration 2759: Loss = 0.17582669854164124\n",
      "Iteration 2809: Loss = 0.7117143273353577\n",
      "Iteration 2859: Loss = 0.5057430267333984\n",
      "Iteration 2909: Loss = 0.6269180178642273\n",
      "Iteration 2959: Loss = 0.5499396920204163\n",
      "Iteration 3009: Loss = 0.3275825083255768\n",
      "Iteration 3061: Loss = 0.7873247861862183\n",
      "Iteration 3111: Loss = 0.6554033160209656\n",
      "Iteration 3161: Loss = 0.5399893522262573\n",
      "Iteration 3211: Loss = 0.7157163023948669\n",
      "Iteration 3261: Loss = 0.18039554357528687\n",
      "Iteration 3311: Loss = 0.6268675327301025\n",
      "Iteration 3361: Loss = 5.960462772236497e-07\n",
      "Iteration 3411: Loss = 0.6996874809265137\n",
      "Iteration 3461: Loss = 0.05104471370577812\n",
      "Iteration 3511: Loss = 0.6620213985443115\n",
      "Iteration 3563: Loss = 0.815021812915802\n",
      "Iteration 3613: Loss = 0.6103113889694214\n",
      "Iteration 3663: Loss = 0.5568979382514954\n",
      "Iteration 3713: Loss = 0.6752285957336426\n",
      "Iteration 3763: Loss = 0.0988440066576004\n",
      "Iteration 3813: Loss = 0.5493310689926147\n",
      "Iteration 3863: Loss = 0.0498477965593338\n",
      "Iteration 3913: Loss = 0.5592527985572815\n",
      "Iteration 3963: Loss = 0.008747130632400513\n",
      "Iteration 4013: Loss = 0.28573721647262573\n",
      "Iteration 4065: Loss = 0.6473497748374939\n",
      "Iteration 4115: Loss = 0.45642518997192383\n",
      "Iteration 4165: Loss = 0.05677740275859833\n",
      "Iteration 4215: Loss = 0.7487567067146301\n",
      "Iteration 4265: Loss = 0.15591645240783691\n",
      "Iteration 4315: Loss = 0.25155210494995117\n",
      "Iteration 4365: Loss = 0.0043265074491500854\n",
      "Iteration 4415: Loss = 0.6256954073905945\n",
      "Iteration 4465: Loss = 0.0025788915809243917\n",
      "Iteration 4515: Loss = 0.4588302969932556\n",
      "Iteration 4567: Loss = 0.5373567938804626\n",
      "Iteration 4617: Loss = 0.5870582461357117\n",
      "Iteration 4667: Loss = 0.03479361534118652\n",
      "Iteration 4717: Loss = 0.30248361825942993\n",
      "Iteration 4767: Loss = 0.06577254831790924\n",
      "Iteration 4817: Loss = 0.2043447196483612\n",
      "Iteration 4867: Loss = 4.6491513785440475e-06\n",
      "Iteration 4917: Loss = 0.9144031405448914\n",
      "Iteration 4967: Loss = 0.0001026698955683969\n",
      "Iteration 5017: Loss = 0.40159928798675537\n",
      "Iteration 5069: Loss = 0.4100376069545746\n",
      "Iteration 5119: Loss = 0.23330745100975037\n",
      "Iteration 5169: Loss = 0.013865811750292778\n",
      "Iteration 5219: Loss = 0.24833811819553375\n",
      "Iteration 5269: Loss = 0.579300582408905\n",
      "Iteration 5319: Loss = 0.1582155078649521\n",
      "Iteration 5369: Loss = 0.002071022754535079\n",
      "Iteration 5419: Loss = 0.882274329662323\n",
      "Iteration 5469: Loss = 2.5470397304161452e-05\n",
      "Iteration 5519: Loss = 0.431474506855011\n",
      "Iteration 5571: Loss = 0.36982792615890503\n",
      "Iteration 5621: Loss = 0.1819961965084076\n",
      "Iteration 5671: Loss = 0.18121442198753357\n",
      "Iteration 5721: Loss = 0.24229295551776886\n",
      "Iteration 5771: Loss = 0.37035655975341797\n",
      "Iteration 5821: Loss = 0.10146408528089523\n",
      "Iteration 5871: Loss = 5.1973900554003194e-05\n",
      "Iteration 5921: Loss = 0.894226610660553\n",
      "Iteration 5971: Loss = 3.083466799580492e-05\n",
      "Iteration 6021: Loss = 0.44890689849853516\n",
      "Iteration 6073: Loss = 0.38397136330604553\n",
      "Iteration 6123: Loss = 0.21609589457511902\n",
      "Iteration 6173: Loss = 0.009102514013648033\n",
      "Iteration 6223: Loss = 0.14613978564739227\n",
      "Iteration 6273: Loss = 0.13145862519741058\n",
      "Iteration 6323: Loss = 0.08798053860664368\n",
      "Iteration 6373: Loss = 2.861018856492592e-06\n",
      "Iteration 6423: Loss = 0.9232897758483887\n",
      "Iteration 6473: Loss = 1.555661037855316e-05\n",
      "Iteration 6523: Loss = 0.5510570406913757\n",
      "Iteration 6575: Loss = 0.35478734970092773\n",
      "Iteration 6625: Loss = 0.1668207198381424\n",
      "Iteration 6675: Loss = 0.008756335824728012\n",
      "Iteration 6725: Loss = 0.1675051599740982\n",
      "Iteration 6775: Loss = 0.31606626510620117\n",
      "Iteration 6825: Loss = 0.16284173727035522\n",
      "Iteration 6875: Loss = 0.0\n",
      "Iteration 6925: Loss = 0.8654895424842834\n",
      "Iteration 6975: Loss = 4.5873443013988435e-05\n",
      "Iteration 7025: Loss = 0.5698285698890686\n",
      "Iteration 7077: Loss = 0.33202695846557617\n",
      "Iteration 7127: Loss = 0.1648215353488922\n",
      "Iteration 7177: Loss = 0.001105650793761015\n",
      "Iteration 7227: Loss = 0.13070212304592133\n",
      "Iteration 7277: Loss = 0.035839833319187164\n",
      "Iteration 7327: Loss = 0.09023801982402802\n",
      "Iteration 7377: Loss = 0.0\n",
      "Iteration 7427: Loss = 0.8166265487670898\n",
      "Iteration 7477: Loss = 1.545715167594608e-05\n",
      "Iteration 7527: Loss = 0.39249885082244873\n",
      "Iteration 7579: Loss = 0.3784303069114685\n",
      "Iteration 7629: Loss = 0.1401415318250656\n",
      "Iteration 7679: Loss = 0.03038572147488594\n",
      "Iteration 7729: Loss = 0.20440702140331268\n",
      "Iteration 7779: Loss = 0.017395325005054474\n",
      "Iteration 7829: Loss = 0.14696469902992249\n",
      "Iteration 7879: Loss = 0.0\n",
      "Iteration 7929: Loss = 0.8664681315422058\n",
      "Iteration 7979: Loss = 8.84394976310432e-05\n",
      "Iteration 8029: Loss = 0.31176888942718506\n",
      "Iteration 8081: Loss = 0.3952468931674957\n",
      "Iteration 8131: Loss = 0.10956946760416031\n",
      "Iteration 8181: Loss = 0.0005443998379632831\n",
      "Iteration 8231: Loss = 0.1255747675895691\n",
      "Iteration 8281: Loss = 0.07989621162414551\n",
      "Iteration 8331: Loss = 0.08532579243183136\n",
      "Iteration 8381: Loss = 0.0\n",
      "Iteration 8431: Loss = 0.7661108374595642\n",
      "Iteration 8481: Loss = 0.0001231383066624403\n",
      "Iteration 8531: Loss = 0.45818912982940674\n",
      "Iteration 8583: Loss = 0.26249295473098755\n",
      "Iteration 8633: Loss = 0.10748247802257538\n",
      "Iteration 8683: Loss = 0.0036465120501816273\n",
      "Iteration 8733: Loss = 0.10836788266897202\n",
      "Iteration 8783: Loss = 1.567577783134766e-05\n",
      "Iteration 8833: Loss = 0.21750585734844208\n",
      "Iteration 8883: Loss = 0.0\n",
      "Iteration 8933: Loss = 0.6573776602745056\n",
      "Iteration 8983: Loss = 0.00045777586637996137\n",
      "Iteration 9033: Loss = 0.43223270773887634\n",
      "Iteration 9085: Loss = 0.32282939553260803\n",
      "Iteration 9135: Loss = 0.07818062603473663\n",
      "Iteration 9185: Loss = 0.0004032037395518273\n",
      "Iteration 9235: Loss = 0.059254974126815796\n",
      "Iteration 9285: Loss = 0.003424649592489004\n",
      "Iteration 9335: Loss = 0.0631965771317482\n",
      "Iteration 9385: Loss = 0.0\n",
      "Iteration 9435: Loss = 0.8592200875282288\n",
      "Iteration 9485: Loss = 0.00021148717496544123\n",
      "Iteration 9535: Loss = 0.3479152023792267\n",
      "Iteration 9587: Loss = 0.3358018696308136\n",
      "Iteration 9637: Loss = 0.10345524549484253\n",
      "Iteration 9687: Loss = 0.20412194728851318\n",
      "Iteration 9737: Loss = 0.18788547813892365\n",
      "Iteration 9787: Loss = 0.25252288579940796\n",
      "Iteration 9837: Loss = 0.13956674933433533\n",
      "Iteration 9887: Loss = 0.0\n",
      "Iteration 9937: Loss = 0.9953891634941101\n",
      "Iteration 9987: Loss = 0.00017561276035849005\n",
      "Iteration 10037: Loss = 0.3943740427494049\n",
      "Iteration 10089: Loss = 0.30502036213874817\n",
      "Iteration 10139: Loss = 0.04754605144262314\n",
      "Iteration 10189: Loss = 0.274901419878006\n",
      "Iteration 10239: Loss = 0.32447436451911926\n",
      "Iteration 10289: Loss = 0.011924396269023418\n",
      "Iteration 10339: Loss = 0.10570308566093445\n",
      "Iteration 10389: Loss = 0.0\n",
      "Iteration 10439: Loss = 0.7758615016937256\n",
      "Iteration 10489: Loss = 0.00020096775551792234\n",
      "Iteration 10539: Loss = 0.5084616541862488\n",
      "Iteration 10591: Loss = 0.3240099251270294\n",
      "Iteration 10641: Loss = 0.028269043192267418\n",
      "Iteration 10691: Loss = 0.004863338079303503\n",
      "Iteration 10741: Loss = 0.346181184053421\n",
      "Iteration 10791: Loss = 5.0960130465682596e-05\n",
      "Iteration 10841: Loss = 0.044344015419483185\n",
      "Iteration 10891: Loss = 0.0\n",
      "Iteration 10941: Loss = 1.0161000490188599\n",
      "Iteration 10991: Loss = 1.54371555254329e-05\n",
      "Iteration 11041: Loss = 0.5495516061782837\n",
      "Iteration 11093: Loss = 0.2185964733362198\n",
      "Iteration 11143: Loss = 0.025811677798628807\n",
      "Iteration 11193: Loss = 0.009097670204937458\n",
      "Iteration 11243: Loss = 0.21656574308872223\n",
      "Iteration 11293: Loss = 0.639210045337677\n",
      "Iteration 11343: Loss = 0.05341922491788864\n",
      "Iteration 11393: Loss = 0.0\n",
      "Iteration 11443: Loss = 0.617730438709259\n",
      "Iteration 11493: Loss = 0.0008308135438710451\n",
      "Iteration 11543: Loss = 0.5534914135932922\n",
      "Iteration 11595: Loss = 0.4207858741283417\n",
      "Iteration 11645: Loss = 0.08648499101400375\n",
      "Iteration 11695: Loss = 0.42969125509262085\n",
      "Iteration 11745: Loss = 0.2243880182504654\n",
      "Iteration 11795: Loss = 0.02710137888789177\n",
      "Iteration 11845: Loss = 0.04293178394436836\n",
      "Iteration 11895: Loss = 0.0\n",
      "Iteration 11945: Loss = 1.012372612953186\n",
      "Iteration 11995: Loss = 0.0022305340971797705\n",
      "Iteration 12045: Loss = 0.3575693368911743\n",
      "Iteration 12097: Loss = 0.344941645860672\n",
      "Iteration 12147: Loss = 0.1470489799976349\n",
      "Iteration 12197: Loss = 0.22106868028640747\n",
      "Iteration 12247: Loss = 0.16193188726902008\n",
      "Iteration 12297: Loss = 0.012530325911939144\n",
      "Iteration 12347: Loss = 0.05753243342041969\n",
      "Iteration 12397: Loss = 0.0\n",
      "Iteration 12447: Loss = 0.5591457486152649\n",
      "Iteration 12497: Loss = 0.00042303596273995936\n",
      "Iteration 12547: Loss = 0.7469884157180786\n",
      "Iteration 12599: Loss = 0.14504416286945343\n",
      "Iteration 12649: Loss = 0.020721852779388428\n",
      "Iteration 12699: Loss = 8.618460560683161e-05\n",
      "Iteration 12749: Loss = 0.33539995551109314\n",
      "Iteration 12799: Loss = 0.04344451427459717\n",
      "Iteration 12849: Loss = 0.049690425395965576\n",
      "Iteration 12899: Loss = 0.0\n",
      "Iteration 12949: Loss = 0.705839216709137\n",
      "Iteration 12999: Loss = 0.000605668465141207\n",
      "Iteration 13049: Loss = 0.26408088207244873\n",
      "Iteration 13101: Loss = 0.3248737156391144\n",
      "Iteration 13151: Loss = 0.04104597866535187\n",
      "Iteration 13201: Loss = 0.19734732806682587\n",
      "Iteration 13251: Loss = 0.10209693759679794\n",
      "Iteration 13301: Loss = 2.6642572265700437e-05\n",
      "Iteration 13351: Loss = 0.03666883707046509\n",
      "Iteration 13401: Loss = 0.0\n",
      "Iteration 13451: Loss = 0.6470474600791931\n",
      "Iteration 13501: Loss = 0.0058592245914042\n",
      "Iteration 13551: Loss = 0.5011395812034607\n",
      "Iteration 13603: Loss = 0.15183699131011963\n",
      "Iteration 13653: Loss = 0.015439948067069054\n",
      "Iteration 13703: Loss = 0.05697358399629593\n",
      "Iteration 13753: Loss = 0.06929486244916916\n",
      "Iteration 13803: Loss = 0.00015506862837355584\n",
      "Iteration 13853: Loss = 0.03443457931280136\n",
      "Iteration 13903: Loss = 0.0\n",
      "Iteration 13953: Loss = 0.6275930404663086\n",
      "Iteration 14003: Loss = 0.0002123017329722643\n",
      "Iteration 14053: Loss = 0.43803754448890686\n",
      "Iteration 14105: Loss = 0.9410430788993835\n",
      "Iteration 14155: Loss = 0.350274920463562\n",
      "Iteration 14205: Loss = 0.05464068055152893\n",
      "Iteration 14255: Loss = 0.1406874805688858\n",
      "Iteration 14305: Loss = 0.00027169878012500703\n",
      "Iteration 14355: Loss = 0.06230399012565613\n",
      "Iteration 14405: Loss = 0.0\n",
      "Iteration 14455: Loss = 0.8638860583305359\n",
      "Iteration 14505: Loss = 0.00037387365591712296\n",
      "Iteration 14555: Loss = 0.1587621569633484\n",
      "Iteration 14607: Loss = 0.11870764195919037\n",
      "Iteration 14657: Loss = 0.04613858088850975\n",
      "Iteration 14707: Loss = 2.53706431388855\n",
      "Iteration 14757: Loss = 0.15391214191913605\n",
      "Iteration 14807: Loss = 0.0002952576905954629\n",
      "Iteration 14857: Loss = 0.04350568726658821\n",
      "Iteration 14907: Loss = 0.0\n",
      "Iteration 14957: Loss = 0.5306930541992188\n",
      "Iteration 15007: Loss = 0.001959757646545768\n",
      "Iteration 15057: Loss = 0.44595038890838623\n",
      "Iteration 15109: Loss = 0.10473515838384628\n",
      "Iteration 15159: Loss = 0.21212556958198547\n",
      "Iteration 15209: Loss = 0.0007638397510163486\n",
      "Iteration 15259: Loss = 0.14108379185199738\n",
      "Iteration 15309: Loss = 0.00010727703192969784\n",
      "Iteration 15359: Loss = 0.023421764373779297\n",
      "Iteration 15409: Loss = 0.0\n",
      "Iteration 15459: Loss = 0.6093288660049438\n",
      "Iteration 15509: Loss = 0.011820755898952484\n",
      "Iteration 15559: Loss = 0.08057525753974915\n",
      "Iteration 15611: Loss = 0.10966331511735916\n",
      "Iteration 15661: Loss = 0.1454886496067047\n",
      "Iteration 15711: Loss = 1.1920928244535389e-07\n",
      "Iteration 15761: Loss = 0.037600550800561905\n",
      "Iteration 15811: Loss = 0.00019880874606315047\n",
      "Iteration 15861: Loss = 0.04399816691875458\n",
      "Iteration 15911: Loss = 0.0\n",
      "Iteration 15961: Loss = 0.6893565058708191\n",
      "Iteration 16011: Loss = 0.0015061795711517334\n",
      "Iteration 16061: Loss = 0.3574756979942322\n",
      "Iteration 16113: Loss = 0.18508635461330414\n",
      "Iteration 16163: Loss = 0.058462630957365036\n",
      "Iteration 16213: Loss = 0.0033280246425420046\n",
      "Iteration 16263: Loss = 0.03788052499294281\n",
      "Iteration 16313: Loss = 8.862424874678254e-05\n",
      "Iteration 16363: Loss = 0.010970178991556168\n",
      "Iteration 16413: Loss = 0.0\n",
      "Iteration 16463: Loss = 0.22552983462810516\n",
      "Iteration 16513: Loss = 0.0038622424472123384\n",
      "Iteration 16563: Loss = 0.7895796895027161\n",
      "Iteration 16615: Loss = 0.16403858363628387\n",
      "Iteration 16665: Loss = 0.09332232177257538\n",
      "Iteration 16715: Loss = 1.490105023549404e-05\n",
      "Iteration 16765: Loss = 0.9607228636741638\n",
      "Iteration 16815: Loss = 6.496863989013946e-06\n",
      "Iteration 16865: Loss = 0.02461165189743042\n",
      "Iteration 16915: Loss = 0.0\n",
      "Iteration 16965: Loss = 0.6805489659309387\n",
      "Iteration 17015: Loss = 0.00256716669537127\n",
      "Iteration 17065: Loss = 0.5556769371032715\n",
      "Iteration 17117: Loss = 0.09946642071008682\n",
      "Iteration 17167: Loss = 0.0502508208155632\n",
      "Iteration 17217: Loss = 0.0010289618512615561\n",
      "Iteration 17267: Loss = 0.016695886850357056\n",
      "Iteration 17317: Loss = 0.0005154336104169488\n",
      "Iteration 17367: Loss = 0.0068831839598715305\n",
      "Iteration 17417: Loss = 0.0\n",
      "Iteration 17467: Loss = 0.6684166789054871\n",
      "Iteration 17517: Loss = 0.005252508912235498\n",
      "Iteration 17567: Loss = 0.20589549839496613\n",
      "Iteration 17619: Loss = 0.12213866412639618\n",
      "Iteration 17669: Loss = 0.011492786929011345\n",
      "Iteration 17719: Loss = 0.0004969792207702994\n",
      "Iteration 17769: Loss = 0.08209405094385147\n",
      "Iteration 17819: Loss = 0.0003681959642563015\n",
      "Iteration 17869: Loss = 0.0016322307055816054\n",
      "Iteration 17919: Loss = 0.0\n",
      "Iteration 17969: Loss = 0.9468271732330322\n",
      "Iteration 18019: Loss = 0.0003291041066404432\n",
      "Iteration 18069: Loss = 0.4541019797325134\n",
      "Iteration 18121: Loss = 0.13955385982990265\n",
      "Iteration 18171: Loss = 0.12327931821346283\n",
      "Iteration 18221: Loss = 0.0013881819322705269\n",
      "Iteration 18271: Loss = 0.803408145904541\n",
      "Iteration 18321: Loss = 0.0006883179303258657\n",
      "Iteration 18371: Loss = 0.016034014523029327\n",
      "Iteration 18421: Loss = 0.0\n",
      "Iteration 18471: Loss = 0.23822247982025146\n",
      "Iteration 18521: Loss = 0.0003793917130678892\n",
      "Iteration 18571: Loss = 0.1344631016254425\n",
      "Iteration 18623: Loss = 0.16037049889564514\n",
      "Iteration 18673: Loss = 0.01651165820658207\n",
      "Iteration 18723: Loss = 9.536738616588991e-07\n",
      "Iteration 18773: Loss = 0.09932121634483337\n",
      "Iteration 18823: Loss = 0.0007481313077732921\n",
      "Iteration 18873: Loss = 0.0050056553445756435\n",
      "Iteration 18923: Loss = 0.0\n",
      "Iteration 18973: Loss = 0.8275488018989563\n",
      "Iteration 19023: Loss = 0.0028656460344791412\n",
      "Iteration 19073: Loss = 0.2296653836965561\n",
      "Iteration 19125: Loss = 0.35624960064888\n",
      "Iteration 19175: Loss = 0.12043068557977676\n",
      "Iteration 19225: Loss = 0.0\n",
      "Iteration 19275: Loss = 0.04468622803688049\n",
      "Iteration 19325: Loss = 0.006579127162694931\n",
      "Iteration 19375: Loss = 0.026321154087781906\n",
      "Iteration 19425: Loss = 0.0\n",
      "Iteration 19475: Loss = 0.15450794994831085\n",
      "Iteration 19525: Loss = 0.0023152318317443132\n",
      "Iteration 19575: Loss = 0.09025706350803375\n",
      "Iteration 19627: Loss = 0.04159317538142204\n",
      "Iteration 19677: Loss = 0.014588591642677784\n",
      "Iteration 19727: Loss = 0.0\n",
      "Iteration 19777: Loss = 0.09871358424425125\n",
      "Iteration 19827: Loss = 1.7881361600302625e-06\n",
      "Iteration 19877: Loss = 0.003533866722136736\n",
      "Iteration 19927: Loss = 0.0\n",
      "Iteration 19977: Loss = 0.7437422871589661\n",
      "Iteration 20027: Loss = 0.003627240424975753\n",
      "Iteration 20077: Loss = 0.12597377598285675\n",
      "Iteration 20129: Loss = 0.0471520833671093\n",
      "Iteration 20179: Loss = 0.002849025186151266\n",
      "Iteration 20229: Loss = 0.0\n",
      "Iteration 20279: Loss = 0.0004495740868151188\n",
      "Iteration 20329: Loss = 0.1924772560596466\n",
      "Iteration 20379: Loss = 0.0011405734112486243\n",
      "Iteration 20429: Loss = 0.0\n",
      "Iteration 20479: Loss = 0.37873372435569763\n",
      "Iteration 20529: Loss = 0.006030248478055\n",
      "Iteration 20579: Loss = 0.050041187554597855\n",
      "Iteration 20631: Loss = 0.04419940710067749\n",
      "Iteration 20681: Loss = 0.0009317059302702546\n",
      "Iteration 20731: Loss = 0.0\n",
      "Iteration 20781: Loss = 0.00038190235500223935\n",
      "Iteration 20831: Loss = 0.20031186938285828\n",
      "Iteration 20881: Loss = 0.013272527605295181\n",
      "Iteration 20931: Loss = 0.0\n",
      "Iteration 20981: Loss = 0.45043495297431946\n",
      "Iteration 21031: Loss = 0.012937000952661037\n",
      "Iteration 21081: Loss = 0.05617043748497963\n",
      "Iteration 21133: Loss = 0.01435905136168003\n",
      "Iteration 21183: Loss = 0.0006743601989001036\n",
      "Iteration 21233: Loss = 0.0\n",
      "Iteration 21283: Loss = 0.0016403893241658807\n",
      "Iteration 21333: Loss = 5.9604641222676946e-08\n",
      "Iteration 21383: Loss = 0.0016494005685672164\n",
      "Iteration 21433: Loss = 0.0\n",
      "Iteration 21483: Loss = 0.46899500489234924\n",
      "Iteration 21533: Loss = 0.0023603085428476334\n",
      "Iteration 21583: Loss = 0.37348631024360657\n",
      "Iteration 21635: Loss = 0.39972516894340515\n",
      "Iteration 21685: Loss = 0.13986286520957947\n",
      "Iteration 21735: Loss = 0.1543334275484085\n",
      "Iteration 21785: Loss = 0.39833760261535645\n",
      "Iteration 21835: Loss = 0.0026779037434607744\n",
      "Iteration 21885: Loss = 0.09436416625976562\n",
      "Iteration 21935: Loss = 0.0\n",
      "Iteration 21985: Loss = 0.5470221638679504\n",
      "Iteration 22035: Loss = 0.0009738872176967561\n",
      "Iteration 22085: Loss = 0.319012314081192\n",
      "Iteration 22137: Loss = 0.18195949494838715\n",
      "Iteration 22187: Loss = 0.034742992371320724\n",
      "Iteration 22237: Loss = 0.008510984480381012\n",
      "Iteration 22287: Loss = 0.09241953492164612\n",
      "Iteration 22337: Loss = 0.00037399845314212143\n",
      "Iteration 22387: Loss = 0.023453934118151665\n",
      "Iteration 22437: Loss = 0.0\n",
      "Iteration 22487: Loss = 0.6391070485115051\n",
      "Iteration 22537: Loss = 0.0015322040999308228\n",
      "Iteration 22587: Loss = 0.3081192672252655\n",
      "Iteration 22639: Loss = 0.08828413486480713\n",
      "Iteration 22689: Loss = 0.041696179658174515\n",
      "Iteration 22739: Loss = 0.00017796363681554794\n",
      "Iteration 22789: Loss = 0.23607361316680908\n",
      "Iteration 22839: Loss = 0.0012819056864827871\n",
      "Iteration 22889: Loss = 0.008441026322543621\n",
      "Iteration 22939: Loss = 0.0\n",
      "Iteration 22989: Loss = 0.07172221690416336\n",
      "Iteration 23039: Loss = 0.010072753764688969\n",
      "Iteration 23089: Loss = 0.12207802385091782\n",
      "Iteration 23141: Loss = 0.6311163306236267\n",
      "Iteration 23191: Loss = 0.01842227578163147\n",
      "Iteration 23241: Loss = 3.8980677345534787e-05\n",
      "Iteration 23291: Loss = 0.00169163488317281\n",
      "Iteration 23341: Loss = 0.006151915527880192\n",
      "Iteration 23391: Loss = 0.002173055661842227\n",
      "Iteration 23441: Loss = 0.0\n",
      "Iteration 23491: Loss = 0.15818087756633759\n",
      "Iteration 23541: Loss = 0.03205661475658417\n",
      "Iteration 23591: Loss = 0.017589768394827843\n",
      "Iteration 23643: Loss = 0.045237086713314056\n",
      "Iteration 23693: Loss = 0.006841843482106924\n",
      "Iteration 23743: Loss = 0.0\n",
      "Iteration 23793: Loss = 0.001596591086126864\n",
      "Iteration 23843: Loss = 7.152552257139178e-07\n",
      "Iteration 23893: Loss = 0.002730580745264888\n",
      "Iteration 23943: Loss = 0.0\n",
      "Iteration 23993: Loss = 0.24145133793354034\n",
      "Iteration 24043: Loss = 0.002723894314840436\n",
      "Iteration 24093: Loss = 0.23345740139484406\n",
      "Iteration 24145: Loss = 0.03650129213929176\n",
      "Iteration 24195: Loss = 0.021185385063290596\n",
      "Iteration 24245: Loss = 3.4570634852570947e-06\n",
      "Iteration 24295: Loss = 0.21763105690479279\n",
      "Iteration 24345: Loss = 0.7460427284240723\n",
      "Iteration 24395: Loss = 0.06372711062431335\n",
      "Iteration 24445: Loss = 0.0\n",
      "Iteration 24495: Loss = 0.2520878314971924\n",
      "Iteration 24545: Loss = 0.0021633619908243418\n",
      "Iteration 24595: Loss = 0.0707070603966713\n",
      "Iteration 24647: Loss = 0.09042440354824066\n",
      "Iteration 24697: Loss = 0.015259897336363792\n",
      "Iteration 24747: Loss = 0.009037541225552559\n",
      "Iteration 24797: Loss = 0.13416676223278046\n",
      "Iteration 24847: Loss = 0.0029557847883552313\n",
      "Iteration 24897: Loss = 0.0012375294463708997\n",
      "Iteration 24947: Loss = 0.0\n",
      "Iteration 24997: Loss = 0.6202477216720581\n",
      "Iteration 25047: Loss = 0.04143691062927246\n",
      "Iteration 25097: Loss = 0.45496490597724915\n",
      "Iteration 25149: Loss = 0.33332017064094543\n",
      "Iteration 25199: Loss = 0.0229203961789608\n",
      "Iteration 25249: Loss = 2.3007127310847864e-05\n",
      "Iteration 25299: Loss = 0.04084702208638191\n",
      "Iteration 25349: Loss = 0.003930241800844669\n",
      "Iteration 25399: Loss = 0.013407392427325249\n",
      "Iteration 25449: Loss = 0.0\n",
      "Iteration 25499: Loss = 0.22138750553131104\n",
      "Iteration 25549: Loss = 0.017786981537938118\n",
      "Iteration 25599: Loss = 0.37660568952560425\n",
      "Iteration 25651: Loss = 0.2763591706752777\n",
      "Iteration 25701: Loss = 0.010758817195892334\n",
      "Iteration 25751: Loss = 0.003097381442785263\n",
      "Iteration 25801: Loss = 0.0018157275626435876\n",
      "Iteration 25851: Loss = 0.00026535638608038425\n",
      "Iteration 25901: Loss = 0.001738575054332614\n",
      "Iteration 25951: Loss = 0.0\n",
      "Iteration 26001: Loss = 0.3837655484676361\n",
      "Iteration 26051: Loss = 0.012091323733329773\n",
      "Iteration 26101: Loss = 0.30077826976776123\n",
      "Iteration 26153: Loss = 0.06318516284227371\n",
      "Iteration 26203: Loss = 0.00343907019123435\n",
      "Iteration 26253: Loss = 0.00019453064305707812\n",
      "Iteration 26303: Loss = 0.6168704628944397\n",
      "Iteration 26353: Loss = 3.6595924029825255e-05\n",
      "Iteration 26403: Loss = 0.026446253061294556\n",
      "Iteration 26453: Loss = 0.0\n",
      "Iteration 26503: Loss = 0.5843212604522705\n",
      "Iteration 26553: Loss = 0.01589941419661045\n",
      "Iteration 26603: Loss = 0.06215406954288483\n",
      "Iteration 26655: Loss = 0.19391264021396637\n",
      "Iteration 26705: Loss = 0.006836751941591501\n",
      "Iteration 26755: Loss = 0.0\n",
      "Iteration 26805: Loss = 0.018930410966277122\n",
      "Iteration 26855: Loss = 0.0015247283736243844\n",
      "Iteration 26905: Loss = 0.0038537196815013885\n",
      "Iteration 26955: Loss = 0.0\n",
      "Iteration 27005: Loss = 0.08969221264123917\n",
      "Iteration 27055: Loss = 0.005469800438731909\n",
      "Iteration 27105: Loss = 0.808799147605896\n",
      "Iteration 27157: Loss = 0.08247322589159012\n",
      "Iteration 27207: Loss = 0.00776383001357317\n",
      "Iteration 27257: Loss = 0.00016819016309455037\n",
      "Iteration 27307: Loss = 0.1369805485010147\n",
      "Iteration 27357: Loss = 0.0005545520107261837\n",
      "Iteration 27407: Loss = 0.005543490406125784\n",
      "Iteration 27457: Loss = 0.0\n",
      "Iteration 27507: Loss = 0.018422460183501244\n",
      "Iteration 27557: Loss = 0.011327569372951984\n",
      "Iteration 27607: Loss = 0.0700693354010582\n",
      "Iteration 27659: Loss = 0.07599896192550659\n",
      "Iteration 27709: Loss = 0.005172022618353367\n",
      "Iteration 27759: Loss = 0.0\n",
      "Iteration 27809: Loss = 0.003535758936777711\n",
      "Iteration 27859: Loss = 0.0018829371547326446\n",
      "Iteration 27909: Loss = 0.005115402862429619\n",
      "Iteration 27959: Loss = 0.0\n",
      "Iteration 28009: Loss = 0.19078479707241058\n",
      "Iteration 28059: Loss = 0.013045082800090313\n",
      "Iteration 28109: Loss = 0.3564359247684479\n",
      "Iteration 28161: Loss = 0.16790960729122162\n",
      "Iteration 28211: Loss = 0.023017380386590958\n",
      "Iteration 28261: Loss = 0.0\n",
      "Iteration 28311: Loss = 0.01231431681662798\n",
      "Iteration 28361: Loss = 0.0006955789867788553\n",
      "Iteration 28411: Loss = 0.009396985173225403\n",
      "Iteration 28461: Loss = 0.0\n",
      "Iteration 28511: Loss = 0.4257074296474457\n",
      "Iteration 28561: Loss = 0.03921792283654213\n",
      "Iteration 28611: Loss = 0.2965323030948639\n",
      "Iteration 28663: Loss = 0.19975067675113678\n",
      "Iteration 28713: Loss = 0.068902388215065\n",
      "Iteration 28763: Loss = 0.004361403174698353\n",
      "Iteration 28813: Loss = 0.003542217193171382\n",
      "Iteration 28863: Loss = 0.0001207444875035435\n",
      "Iteration 28913: Loss = 0.0429721437394619\n",
      "Iteration 28963: Loss = 0.0\n",
      "Iteration 29013: Loss = 0.05264251306653023\n",
      "Iteration 29063: Loss = 0.0023767200764268637\n",
      "Iteration 29113: Loss = 0.1262984275817871\n",
      "Iteration 29165: Loss = 0.018923630937933922\n",
      "Iteration 29215: Loss = 0.0044343238696455956\n",
      "Iteration 29265: Loss = 1.1920928244535389e-07\n",
      "Iteration 29315: Loss = 0.0032341089099645615\n",
      "Iteration 29365: Loss = 2.3556900024414062\n",
      "Iteration 29415: Loss = 0.0331619456410408\n",
      "Iteration 29465: Loss = 0.0\n",
      "Iteration 29515: Loss = 0.2976461946964264\n",
      "Iteration 29565: Loss = 0.0024860533885657787\n",
      "Iteration 29615: Loss = 0.48630034923553467\n",
      "Iteration 29667: Loss = 0.34487634897232056\n",
      "Iteration 29717: Loss = 0.00483125913888216\n",
      "Iteration 29767: Loss = 0.0\n",
      "Iteration 29817: Loss = 0.001915253815241158\n",
      "Iteration 29867: Loss = 0.003690240904688835\n",
      "Iteration 29917: Loss = 0.005705702118575573\n",
      "Iteration 29967: Loss = 0.0\n",
      "Iteration 30017: Loss = 0.22693879902362823\n",
      "Iteration 30067: Loss = 0.008991544134914875\n",
      "Iteration 30117: Loss = 0.17307911813259125\n",
      "Iteration 30169: Loss = 0.17610681056976318\n",
      "Iteration 30219: Loss = 1.2206593751907349\n",
      "Iteration 30269: Loss = 0.16903990507125854\n",
      "Iteration 30319: Loss = 0.008915020152926445\n",
      "Iteration 30369: Loss = 0.2809080481529236\n",
      "Iteration 30419: Loss = 0.003126793308183551\n",
      "Iteration 30469: Loss = 0.0\n",
      "Iteration 30519: Loss = 0.28525209426879883\n",
      "Iteration 30569: Loss = 0.00568094477057457\n",
      "Iteration 30619: Loss = 0.1673128455877304\n",
      "Iteration 30671: Loss = 0.106632761657238\n",
      "Iteration 30721: Loss = 0.003943803254514933\n",
      "Iteration 30771: Loss = 0.00020787939138244838\n",
      "Iteration 30821: Loss = 0.004587592091411352\n",
      "Iteration 30871: Loss = 0.0\n",
      "Iteration 30921: Loss = 0.020187484100461006\n",
      "Iteration 30971: Loss = 0.0\n",
      "Iteration 31021: Loss = 0.22306354343891144\n",
      "Iteration 31071: Loss = 0.009027034044265747\n",
      "Iteration 31121: Loss = 0.0587649941444397\n",
      "Iteration 31173: Loss = 0.026329917833209038\n",
      "Iteration 31223: Loss = 0.15859581530094147\n",
      "Iteration 31273: Loss = 0.0\n",
      "Iteration 31323: Loss = 0.003426451003178954\n",
      "Iteration 31373: Loss = 1.6093227941382793e-06\n",
      "Iteration 31423: Loss = 5.441607936518267e-05\n",
      "Iteration 31473: Loss = 0.0\n",
      "Iteration 31523: Loss = 0.25563088059425354\n",
      "Iteration 31573: Loss = 0.03212055191397667\n",
      "Iteration 31623: Loss = 0.023588914424180984\n",
      "Iteration 31675: Loss = 0.18038763105869293\n",
      "Iteration 31725: Loss = 0.009313336573541164\n",
      "Iteration 31775: Loss = 0.0\n",
      "Iteration 31825: Loss = 0.0005712918937206268\n",
      "Iteration 31875: Loss = 0.0\n",
      "Iteration 31925: Loss = 0.0004100541409570724\n",
      "Iteration 31975: Loss = 0.0\n",
      "Iteration 32025: Loss = 0.6325953602790833\n",
      "Iteration 32075: Loss = 0.569115936756134\n",
      "Iteration 32125: Loss = 0.38165250420570374\n",
      "Iteration 32177: Loss = 0.6283930540084839\n",
      "Iteration 32227: Loss = 0.3263985514640808\n",
      "Iteration 32277: Loss = 0.2135431319475174\n",
      "Iteration 32327: Loss = 0.08920446783304214\n",
      "Iteration 32377: Loss = 0.0008183986647054553\n",
      "Iteration 32427: Loss = 0.009816117584705353\n",
      "Iteration 32477: Loss = 0.0\n",
      "Iteration 32527: Loss = 0.0834580734372139\n",
      "Iteration 32577: Loss = 0.0008721169433556497\n",
      "Iteration 32627: Loss = 0.4909939765930176\n",
      "Iteration 32679: Loss = 0.15827253460884094\n",
      "Iteration 32729: Loss = 0.026668060570955276\n",
      "Iteration 32779: Loss = 2.861018856492592e-06\n",
      "Iteration 32829: Loss = 0.003952365834265947\n",
      "Iteration 32879: Loss = 1.7881372968986398e-06\n",
      "Iteration 32929: Loss = 0.0026750501710921526\n",
      "Iteration 32979: Loss = 0.0\n",
      "Iteration 33029: Loss = 0.03423663601279259\n",
      "Iteration 33079: Loss = 0.002331254305317998\n",
      "Iteration 33129: Loss = 0.330096036195755\n",
      "Iteration 33181: Loss = 0.07448936253786087\n",
      "Iteration 33231: Loss = 0.0610540509223938\n",
      "Iteration 33281: Loss = 0.0\n",
      "Iteration 33331: Loss = 0.0032229528296738863\n",
      "Iteration 33381: Loss = 6.377656518452568e-06\n",
      "Iteration 33431: Loss = 0.0005325448582880199\n",
      "Iteration 33481: Loss = 0.0\n",
      "Iteration 33531: Loss = 0.02029588632285595\n",
      "Iteration 33581: Loss = 0.008948388509452343\n",
      "Iteration 33631: Loss = 0.1501546949148178\n",
      "Iteration 33683: Loss = 0.017515035346150398\n",
      "Iteration 33733: Loss = 0.0015490081859752536\n",
      "Iteration 33783: Loss = 1.1920928244535389e-07\n",
      "Iteration 33833: Loss = 0.0015710709849372506\n",
      "Iteration 33883: Loss = 7.569732588308398e-06\n",
      "Iteration 33933: Loss = 0.00107274588663131\n",
      "Iteration 33983: Loss = 0.0\n",
      "Iteration 34033: Loss = 0.012468528933823109\n",
      "Iteration 34083: Loss = 0.0009444982861168683\n",
      "Iteration 34133: Loss = 0.21214383840560913\n",
      "Iteration 34185: Loss = 0.08372490853071213\n",
      "Iteration 34235: Loss = 0.14826050400733948\n",
      "Iteration 34285: Loss = 0.0\n",
      "Iteration 34335: Loss = 0.04659457132220268\n",
      "Iteration 34385: Loss = 0.0003436860570218414\n",
      "Iteration 34435: Loss = 0.035008467733860016\n",
      "Iteration 34485: Loss = 0.0\n",
      "Iteration 34535: Loss = 0.16647064685821533\n",
      "Iteration 34585: Loss = 0.007892060093581676\n",
      "Iteration 34635: Loss = 0.05341828987002373\n",
      "Iteration 34687: Loss = 0.1303725689649582\n",
      "Iteration 34737: Loss = 0.1575864553451538\n",
      "Iteration 34787: Loss = 0.00010632903286023065\n",
      "Iteration 34837: Loss = 0.044788237661123276\n",
      "Iteration 34887: Loss = 8.94068989509833e-07\n",
      "Iteration 34937: Loss = 0.020602300763130188\n",
      "Iteration 34987: Loss = 0.0\n",
      "Iteration 35037: Loss = 0.6441503763198853\n",
      "Iteration 35087: Loss = 0.002169608138501644\n",
      "Iteration 35137: Loss = 0.07685419172048569\n",
      "Iteration 35189: Loss = 0.38059568405151367\n",
      "Iteration 35239: Loss = 0.006289431359618902\n",
      "Iteration 35289: Loss = 7.152555099310121e-07\n",
      "Iteration 35339: Loss = 0.33145105838775635\n",
      "Iteration 35389: Loss = 0.000249561999225989\n",
      "Iteration 35439: Loss = 0.012096057645976543\n",
      "Iteration 35489: Loss = 0.0\n",
      "Iteration 35539: Loss = 0.10194835811853409\n",
      "Iteration 35589: Loss = 0.0024807897862046957\n",
      "Iteration 35639: Loss = 0.21429353952407837\n",
      "Iteration 35691: Loss = 0.12787190079689026\n",
      "Iteration 35741: Loss = 0.008777445182204247\n",
      "Iteration 35791: Loss = 1.9311717551317997e-05\n",
      "Iteration 35841: Loss = 0.0167961735278368\n",
      "Iteration 35891: Loss = 5.9604641222676946e-08\n",
      "Iteration 35941: Loss = 0.013998120091855526\n",
      "Iteration 35991: Loss = 0.0\n",
      "Iteration 36041: Loss = 1.2546340227127075\n",
      "Iteration 36091: Loss = 0.003979558125138283\n",
      "Iteration 36141: Loss = 0.46401315927505493\n",
      "Iteration 36193: Loss = 0.0638544037938118\n",
      "Iteration 36243: Loss = 0.04021144658327103\n",
      "Iteration 36293: Loss = 0.0010550415609031916\n",
      "Iteration 36343: Loss = 0.01956372894346714\n",
      "Iteration 36393: Loss = 0.0005453473422676325\n",
      "Iteration 36443: Loss = 0.017681816592812538\n",
      "Iteration 36493: Loss = 0.0\n",
      "Iteration 36543: Loss = 0.23797409236431122\n",
      "Iteration 36593: Loss = 0.003127879463136196\n",
      "Iteration 36643: Loss = 0.17194251716136932\n",
      "Iteration 36695: Loss = 0.023548167198896408\n",
      "Iteration 36745: Loss = 0.0071555450558662415\n",
      "Iteration 36795: Loss = 0.0\n",
      "Iteration 36845: Loss = 0.012759841978549957\n",
      "Iteration 36895: Loss = 1.4483823179034516e-05\n",
      "Iteration 36945: Loss = 0.016518035903573036\n",
      "Iteration 36995: Loss = 0.0\n",
      "Iteration 37045: Loss = 0.01608871854841709\n",
      "Iteration 37095: Loss = 0.005857957061380148\n",
      "Iteration 37145: Loss = 0.024306751787662506\n",
      "Iteration 37197: Loss = 0.01916578784584999\n",
      "Iteration 37247: Loss = 0.002803945913910866\n",
      "Iteration 37297: Loss = 0.0\n",
      "Iteration 37347: Loss = 0.0038214223459362984\n",
      "Iteration 37397: Loss = 9.953879271051846e-06\n",
      "Iteration 37447: Loss = 0.00747824739664793\n",
      "Iteration 37497: Loss = 0.0\n",
      "Iteration 37547: Loss = 0.0008858868386596441\n",
      "Iteration 37597: Loss = 0.001399514265358448\n",
      "Iteration 37647: Loss = 0.02555128186941147\n",
      "Iteration 37699: Loss = 0.008336394093930721\n",
      "Iteration 37749: Loss = 0.27581581473350525\n",
      "Iteration 37799: Loss = 0.0002330270071979612\n",
      "Iteration 37849: Loss = 0.013915606774389744\n",
      "Iteration 37899: Loss = 0.0\n",
      "Iteration 37949: Loss = 0.022754639387130737\n",
      "Iteration 37999: Loss = 0.0\n",
      "Iteration 38049: Loss = 0.10743597149848938\n",
      "Iteration 38099: Loss = 0.0015141945332288742\n",
      "Iteration 38149: Loss = 0.020342379808425903\n",
      "Iteration 38201: Loss = 0.02546517737209797\n",
      "Iteration 38251: Loss = 0.0022414580453187227\n",
      "Iteration 38301: Loss = 2.3841855067985307e-07\n",
      "Iteration 38351: Loss = 0.0050474368035793304\n",
      "Iteration 38401: Loss = 1.966951458598487e-06\n",
      "Iteration 38451: Loss = 0.0053292675875127316\n",
      "Iteration 38501: Loss = 0.0\n",
      "Iteration 38551: Loss = 0.03627532348036766\n",
      "Iteration 38601: Loss = 0.003117299871519208\n",
      "Iteration 38651: Loss = 0.005749433767050505\n",
      "Iteration 38703: Loss = 0.08114631474018097\n",
      "Iteration 38753: Loss = 0.0015807680319994688\n",
      "Iteration 38803: Loss = 1.0013530300057027e-05\n",
      "Iteration 38853: Loss = 0.0018970239907503128\n",
      "Iteration 38903: Loss = 0.0006019245483912528\n",
      "Iteration 38953: Loss = 0.0034698154777288437\n",
      "Iteration 39003: Loss = 0.0\n",
      "Iteration 39053: Loss = 0.2809334695339203\n",
      "Iteration 39103: Loss = 0.009363984689116478\n",
      "Iteration 39153: Loss = 0.011794669553637505\n",
      "Iteration 39205: Loss = 0.23515434563159943\n",
      "Iteration 39255: Loss = 0.30969399213790894\n",
      "Iteration 39305: Loss = 0.0004109491710551083\n",
      "Iteration 39355: Loss = 0.010852906852960587\n",
      "Iteration 39405: Loss = 3.7668720324290916e-05\n",
      "Iteration 39455: Loss = 0.008875466883182526\n",
      "Iteration 39505: Loss = 0.0\n",
      "Iteration 39555: Loss = 0.086402527987957\n",
      "Iteration 39605: Loss = 0.0020499795209616423\n",
      "Iteration 39655: Loss = 0.2641444802284241\n",
      "Iteration 39707: Loss = 0.005862444639205933\n",
      "Iteration 39757: Loss = 0.16882655024528503\n",
      "Iteration 39807: Loss = 9.298280929215252e-06\n",
      "Iteration 39857: Loss = 0.00766742741689086\n",
      "Iteration 39907: Loss = 3.5404191294219345e-05\n",
      "Iteration 39957: Loss = 0.011502878740429878\n",
      "Iteration 40007: Loss = 0.0\n",
      "Iteration 40057: Loss = 0.0278040561825037\n",
      "Iteration 40107: Loss = 5.016388968215324e-05\n",
      "Iteration 40157: Loss = 0.03527499735355377\n",
      "Iteration 40209: Loss = 0.014174914918839931\n",
      "Iteration 40259: Loss = 0.1524955928325653\n",
      "Iteration 40309: Loss = 0.07700479030609131\n",
      "Iteration 40359: Loss = 0.04976332187652588\n",
      "Iteration 40409: Loss = 0.0010947514092549682\n",
      "Iteration 40459: Loss = 0.023671679198741913\n",
      "Iteration 40509: Loss = 0.0\n",
      "Iteration 40559: Loss = 0.14151327311992645\n",
      "Iteration 40609: Loss = 0.0021763837430626154\n",
      "Iteration 40659: Loss = 0.14430370926856995\n",
      "Iteration 40711: Loss = 0.12033835798501968\n",
      "Iteration 40761: Loss = 0.003998265601694584\n",
      "Iteration 40811: Loss = 4.0531076592742465e-06\n",
      "Iteration 40861: Loss = 0.006391389761120081\n",
      "Iteration 40911: Loss = 0.00011609731882344931\n",
      "Iteration 40961: Loss = 0.008264780975878239\n",
      "Iteration 41011: Loss = 0.0\n",
      "Iteration 41061: Loss = 0.04804406687617302\n",
      "Iteration 41111: Loss = 0.015700766816735268\n",
      "Iteration 41161: Loss = 0.0014051995240151882\n",
      "Iteration 41213: Loss = 0.02738758735358715\n",
      "Iteration 41263: Loss = 0.27515947818756104\n",
      "Iteration 41313: Loss = 9.059865078597795e-06\n",
      "Iteration 41363: Loss = 0.003725439077243209\n",
      "Iteration 41413: Loss = 0.0027071726508438587\n",
      "Iteration 41463: Loss = 0.011644713580608368\n",
      "Iteration 41513: Loss = 0.0\n",
      "Iteration 41563: Loss = 0.03500346466898918\n",
      "Iteration 41613: Loss = 0.009550413116812706\n",
      "Iteration 41663: Loss = 0.034849200397729874\n",
      "Iteration 41715: Loss = 0.035905707627534866\n",
      "Iteration 41765: Loss = 0.003407467156648636\n",
      "Iteration 41815: Loss = 0.0\n",
      "Iteration 41865: Loss = 0.0003687978023663163\n",
      "Iteration 41915: Loss = 4.41073007095838e-06\n",
      "Iteration 41965: Loss = 0.007155000697821379\n",
      "Iteration 42015: Loss = 0.0\n",
      "Iteration 42065: Loss = 0.8224826455116272\n",
      "Iteration 42115: Loss = 0.00584004120901227\n",
      "Iteration 42165: Loss = 0.01886386051774025\n",
      "Iteration 42217: Loss = 0.20446190237998962\n",
      "Iteration 42267: Loss = 0.6661797761917114\n",
      "Iteration 42317: Loss = 1.4305012882687151e-05\n",
      "Iteration 42367: Loss = 0.0042040529660880566\n",
      "Iteration 42417: Loss = 2.14576334656158e-06\n",
      "Iteration 42467: Loss = 0.012007428333163261\n",
      "Iteration 42517: Loss = 0.0\n",
      "Iteration 42567: Loss = 0.007990960963070393\n",
      "Iteration 42617: Loss = 0.03725084289908409\n",
      "Iteration 42667: Loss = 0.016775179654359818\n",
      "Iteration 42719: Loss = 0.03167242929339409\n",
      "Iteration 42769: Loss = 0.002938914578408003\n",
      "Iteration 42819: Loss = 0.0\n",
      "Iteration 42869: Loss = 0.0010461390484124422\n",
      "Iteration 42919: Loss = 7.629362698935438e-06\n",
      "Iteration 42969: Loss = 0.003942067734897137\n",
      "Iteration 43019: Loss = 0.0\n",
      "Iteration 43069: Loss = 0.0005605517071671784\n",
      "Iteration 43119: Loss = 0.005642462521791458\n",
      "Iteration 43169: Loss = 0.014132414013147354\n",
      "Iteration 43221: Loss = 0.010899265296757221\n",
      "Iteration 43271: Loss = 0.0031999717466533184\n",
      "Iteration 43321: Loss = 0.0\n",
      "Iteration 43371: Loss = 0.0002306955138919875\n",
      "Iteration 43421: Loss = 3.808591645793058e-05\n",
      "Iteration 43471: Loss = 0.004343070089817047\n",
      "Iteration 43521: Loss = 0.0\n",
      "Iteration 43571: Loss = 0.0023642859887331724\n",
      "Iteration 43621: Loss = 0.007827225141227245\n",
      "Iteration 43671: Loss = 0.08607599139213562\n",
      "Iteration 43723: Loss = 0.014200837351381779\n",
      "Iteration 43773: Loss = 0.004378244746476412\n",
      "Iteration 43823: Loss = 0.0\n",
      "Iteration 43873: Loss = 0.002408840926364064\n",
      "Iteration 43923: Loss = 1.7881390590446244e-07\n",
      "Iteration 43973: Loss = 0.005419106688350439\n",
      "Iteration 44023: Loss = 0.0\n",
      "Iteration 44073: Loss = 0.000551544304471463\n",
      "Iteration 44123: Loss = 0.00028837882564403117\n",
      "Iteration 44173: Loss = 0.04709860682487488\n",
      "Iteration 44225: Loss = 0.004246396943926811\n",
      "Iteration 44275: Loss = 0.0012307132128626108\n",
      "Iteration 44325: Loss = 0.0\n",
      "Iteration 44375: Loss = 0.0010497277835384011\n",
      "Iteration 44425: Loss = 0.0\n",
      "Iteration 44475: Loss = 0.0011567791225388646\n",
      "Iteration 44525: Loss = 0.0\n",
      "Iteration 44575: Loss = 0.00011227724462514743\n",
      "Iteration 44625: Loss = 0.0006862357840873301\n",
      "Iteration 44675: Loss = 0.021208375692367554\n",
      "Iteration 44727: Loss = 0.0017655660631135106\n",
      "Iteration 44777: Loss = 0.0010527748381718993\n",
      "Iteration 44827: Loss = 0.0\n",
      "Iteration 44877: Loss = 0.0005328930565156043\n",
      "Iteration 44927: Loss = 0.0\n",
      "Iteration 44977: Loss = 0.004753748420625925\n",
      "Iteration 45027: Loss = 0.0\n",
      "Iteration 45077: Loss = 4.922617881675251e-05\n",
      "Iteration 45127: Loss = 0.0006519125890918076\n",
      "Iteration 45177: Loss = 0.0026647583581507206\n",
      "Iteration 45229: Loss = 0.0010898124892264605\n",
      "Iteration 45279: Loss = 0.0001825929357437417\n",
      "Iteration 45329: Loss = 0.0\n",
      "Iteration 45379: Loss = 0.00034080594195984304\n",
      "Iteration 45429: Loss = 0.0\n",
      "Iteration 45479: Loss = 0.002621383173391223\n",
      "Iteration 45529: Loss = 0.0\n",
      "Iteration 45579: Loss = 7.94728478581419e-08\n",
      "Iteration 45629: Loss = 0.00029112977790646255\n",
      "Iteration 45679: Loss = 0.003144840942695737\n",
      "Iteration 45731: Loss = 0.0007530520088039339\n",
      "Iteration 45781: Loss = 6.772325286874548e-05\n",
      "Iteration 45831: Loss = 0.0\n",
      "Iteration 45881: Loss = 0.0001952475286088884\n",
      "Iteration 45931: Loss = 0.0\n",
      "Iteration 45981: Loss = 0.001087673706933856\n",
      "Iteration 46031: Loss = 0.0\n",
      "Iteration 46081: Loss = 5.9604641222676946e-08\n",
      "Iteration 46131: Loss = 0.0001206712840939872\n",
      "Iteration 46181: Loss = 0.0008324260707013309\n",
      "Iteration 46233: Loss = 0.0006007208139635623\n",
      "Iteration 46283: Loss = 4.5032200432615355e-05\n",
      "Iteration 46333: Loss = 0.0\n",
      "Iteration 46383: Loss = 0.0001501302031101659\n",
      "Iteration 46433: Loss = 0.0\n",
      "Iteration 46483: Loss = 0.0007731893565505743\n",
      "Iteration 46533: Loss = 0.0\n",
      "Iteration 46583: Loss = 1.9868213740892315e-08\n",
      "Iteration 46633: Loss = 6.160375050967559e-05\n",
      "Iteration 46683: Loss = 0.00046917630243115127\n",
      "Iteration 46735: Loss = 0.0004952288581989706\n",
      "Iteration 46785: Loss = 3.235078474972397e-05\n",
      "Iteration 46835: Loss = 0.0\n",
      "Iteration 46885: Loss = 0.00011883049592142925\n",
      "Iteration 46935: Loss = 0.0\n",
      "Iteration 46985: Loss = 0.0005914050270803273\n",
      "Iteration 47035: Loss = 0.0\n",
      "Iteration 47085: Loss = 1.9868213740892315e-08\n",
      "Iteration 47135: Loss = 3.6952082155039534e-05\n",
      "Iteration 47185: Loss = 0.00031627932912670076\n",
      "Iteration 47237: Loss = 0.00041720079025253654\n",
      "Iteration 47287: Loss = 2.4341055905097164e-05\n",
      "Iteration 47337: Loss = 0.0\n",
      "Iteration 47387: Loss = 9.678390779299662e-05\n",
      "Iteration 47437: Loss = 0.0\n",
      "Iteration 47487: Loss = 0.0004664867010433227\n",
      "Iteration 47537: Loss = 0.0\n",
      "Iteration 47587: Loss = 0.0\n",
      "Iteration 47637: Loss = 2.4357190341106616e-05\n",
      "Iteration 47687: Loss = 0.00023311602126341313\n",
      "Iteration 47739: Loss = 0.0003574717266019434\n",
      "Iteration 47789: Loss = 1.888185943244025e-05\n",
      "Iteration 47839: Loss = 0.0\n",
      "Iteration 47889: Loss = 8.02579234004952e-05\n",
      "Iteration 47939: Loss = 0.0\n",
      "Iteration 47989: Loss = 0.00037608304410241544\n",
      "Iteration 48039: Loss = 0.0\n",
      "Iteration 48089: Loss = 0.0\n",
      "Iteration 48139: Loss = 1.706617695163004e-05\n",
      "Iteration 48189: Loss = 0.00018260625074617565\n",
      "Iteration 48241: Loss = 0.0003104897041339427\n",
      "Iteration 48291: Loss = 1.5067486856423784e-05\n",
      "Iteration 48341: Loss = 0.0\n",
      "Iteration 48391: Loss = 6.754508649464697e-05\n",
      "Iteration 48441: Loss = 0.0\n",
      "Iteration 48491: Loss = 0.00031074165599420667\n",
      "Iteration 48541: Loss = 0.0\n",
      "Iteration 48591: Loss = 0.0\n",
      "Iteration 48641: Loss = 1.2476902156777214e-05\n",
      "Iteration 48691: Loss = 0.00015001490828581154\n",
      "Iteration 48743: Loss = 0.00027307908749207854\n",
      "Iteration 48793: Loss = 1.2278180292923935e-05\n",
      "Iteration 48843: Loss = 0.0\n",
      "Iteration 48893: Loss = 5.7692304835654795e-05\n",
      "Iteration 48943: Loss = 0.0\n",
      "Iteration 48993: Loss = 0.000260285334661603\n",
      "Iteration 49043: Loss = 0.0\n",
      "Iteration 49093: Loss = 0.0\n",
      "Iteration 49143: Loss = 9.457074156671297e-06\n",
      "Iteration 49193: Loss = 0.00012518205039668828\n",
      "Iteration 49245: Loss = 0.00024241891514975578\n",
      "Iteration 49295: Loss = 1.0180214303545654e-05\n",
      "Iteration 49345: Loss = 0.0\n",
      "Iteration 49395: Loss = 4.98257577419281e-05\n",
      "Iteration 49445: Loss = 0.0\n",
      "Iteration 49495: Loss = 0.00022126307885628194\n",
      "Iteration 49545: Loss = 0.0\n",
      "Iteration 49595: Loss = 0.0\n",
      "Iteration 49645: Loss = 7.370987077592872e-06\n",
      "Iteration 49695: Loss = 0.00010708008630899712\n",
      "Iteration 49747: Loss = 0.00021713286696467549\n",
      "Iteration 49797: Loss = 8.535203050996643e-06\n",
      "Iteration 49847: Loss = 0.0\n",
      "Iteration 49897: Loss = 4.3468822696013376e-05\n",
      "Iteration 49947: Loss = 0.0\n",
      "Iteration 49997: Loss = 0.00019087723921984434\n",
      "Iteration 50047: Loss = 0.0\n",
      "Iteration 50097: Loss = 0.0\n",
      "Iteration 50147: Loss = 5.880914159206441e-06\n",
      "Iteration 50197: Loss = 9.374003275297582e-05\n"
     ]
    },
    {
<<<<<<< HEAD
     "output_type": "error",
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-0117b7f76f31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-9a483ab86aa2>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(model, dataloader, optimizer, epochs, device, save_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iter\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_model.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
=======
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "train_classifier(model, trainloader, optimizer, epochs, device, \"model_weights/pretrained\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p9Z_1EFllBgV",
        "outputId": "5d81479c-7c6b-434f-bce3-a40fbf6bfa93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 199: Loss = 0.7168130278587341\n",
            "Iteration 399: Loss = 0.5851792693138123\n",
            "Iteration 701: Loss = 0.7531083226203918\n",
            "Iteration 901: Loss = 0.6314525008201599\n",
            "Iteration 1203: Loss = 0.7489344477653503\n",
            "Iteration 1403: Loss = 0.5780285000801086\n",
            "Iteration 1705: Loss = 0.7614888548851013\n",
            "Iteration 1905: Loss = 0.6236931085586548\n",
            "Iteration 2207: Loss = 0.7548441290855408\n",
            "Iteration 2407: Loss = 0.5963820815086365\n",
            "Iteration 2709: Loss = 0.7581562995910645\n",
            "Iteration 2909: Loss = 0.5867300033569336\n",
            "Iteration 3211: Loss = 0.7525709271430969\n",
            "Iteration 3411: Loss = 0.5757452845573425\n",
            "Iteration 3713: Loss = 0.6598060727119446\n",
            "Iteration 3913: Loss = 0.5690398216247559\n",
            "Iteration 4215: Loss = 0.022593608126044273\n",
            "Iteration 4415: Loss = 0.5575740337371826\n",
            "Iteration 4717: Loss = 0.18011169135570526\n",
            "Iteration 4917: Loss = 0.5598032474517822\n",
            "Iteration 5219: Loss = 0.21478445827960968\n",
            "Iteration 5419: Loss = 0.47238364815711975\n",
            "Iteration 5721: Loss = 0.02652120031416416\n",
            "Iteration 5921: Loss = 0.4299851655960083\n",
            "Iteration 6223: Loss = 0.1392771601676941\n",
            "Iteration 6423: Loss = 0.7858474850654602\n",
            "Iteration 6725: Loss = 0.1664404720067978\n",
            "Iteration 6925: Loss = 0.5200234651565552\n",
            "Iteration 7227: Loss = 0.06493737548589706\n",
            "Iteration 7427: Loss = 0.30327415466308594\n",
            "Iteration 7729: Loss = 0.034429240971803665\n",
            "Iteration 7929: Loss = 0.3254951536655426\n",
            "Iteration 8231: Loss = 0.0611611008644104\n",
            "Iteration 8431: Loss = 0.9525273442268372\n",
            "Iteration 8733: Loss = 0.7206384539604187\n",
            "Iteration 8933: Loss = 0.6161705851554871\n",
            "Iteration 9235: Loss = 0.7600307464599609\n",
            "Iteration 9435: Loss = 0.600620687007904\n",
            "Iteration 9737: Loss = 0.7632598280906677\n",
            "Iteration 9937: Loss = 0.5994606018066406\n",
            "Iteration 10239: Loss = 0.763687789440155\n",
            "Iteration 10439: Loss = 0.5986944437026978\n",
            "Iteration 10741: Loss = 0.7643022537231445\n",
            "Iteration 10941: Loss = 0.5961857438087463\n",
            "Iteration 11243: Loss = 0.5449294447898865\n",
            "Iteration 11443: Loss = 0.5828675627708435\n",
            "Iteration 11745: Loss = 0.7673769593238831\n",
            "Iteration 11945: Loss = 0.5981781482696533\n",
            "Iteration 12247: Loss = 0.7643772959709167\n",
            "Iteration 12447: Loss = 0.5950348973274231\n",
            "Iteration 12749: Loss = 0.7646464705467224\n",
            "Iteration 12949: Loss = 0.5985522270202637\n",
            "Iteration 13251: Loss = 0.7650019526481628\n",
            "Iteration 13451: Loss = 0.5911365151405334\n",
            "Iteration 13753: Loss = 0.37988099455833435\n",
            "Iteration 13953: Loss = 0.4850254952907562\n",
            "Iteration 14255: Loss = 0.47832635045051575\n",
            "Iteration 14455: Loss = 0.7388718128204346\n",
            "Iteration 14757: Loss = 0.3670888841152191\n",
            "Iteration 14957: Loss = 0.25934842228889465\n",
            "Iteration 15259: Loss = 0.08234596997499466\n",
            "Iteration 15459: Loss = 0.45097577571868896\n",
            "Iteration 15761: Loss = 0.1941201537847519\n",
            "Iteration 15961: Loss = 0.5675013065338135\n",
            "Iteration 16263: Loss = 0.029823003336787224\n",
            "Iteration 16463: Loss = 0.6708338856697083\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-89d1441e01af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_weights/pretrained\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-eda59be8eba5>\u001b[0m in \u001b[0;36mtrain_classifier\u001b[0;34m(model, dataloader, optimizer, epochs, device, save_dir)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-eda59be8eba5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "noBmLUH0zu0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, testloader, device):\n",
        "\n",
        "  n_total = 0\n",
        "  n_correct = 0\n",
        "\n",
        "  p = []\n",
        "  l = []\n",
        "\n",
        "  for data, labels in testloader:\n",
        "\n",
        "    data = [d.to(device) for d in data]\n",
        "    labels = torch.LongTensor(labels).to(device)\n",
        "\n",
        "    preds = model(data)\n",
        "    preds = [pred[0] for pred in preds]\n",
        "    preds = torch.cat(preds)\n",
        "    preds = F.softmax(preds, dim=1)\n",
        "    preds = torch.argmax(preds, dim=1)\n",
        "\n",
        "    p += list(preds)\n",
        "    l += list(labels)\n",
        "\n",
        "    n_correct += torch.sum(torch.eq(preds, labels))\n",
        "    n_total += len(labels)\n",
        "\n",
        "  accuracy = (n_correct/n_total)*100\n",
        "  print(f\"Accuracy: {accuracy}%\")\n",
        "\n",
        "  p = [i.cpu().item() for i in p]\n",
        "  l = [i.cpu().item() for i in l]\n",
        "\n",
        "  return accuracy.item(), p, l"
      ],
      "metadata": {
        "id": "PUZssVnRROky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = PictorPPEDataset(\"data/Images\", \"data/Labels/pictor_ppe_crowdsourced_approach-02_test.txt\")\n",
        "testloader = DataLoader(test_dataset, batch_size=1)\n",
        "len(test_dataset), len(testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdQ0uqfbzuXl",
        "outputId": "aca60c08-3ae8-485f-ea3d-e2afaa61ebf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(152, 152)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = ClassificationModel((96, 32), 1536, (512, 128), 1)\n",
        "model.load_state_dict(torch.load(\"model_weights/scratch/best_model.pth\", map_location=\"cpu\"))\n",
        "model.eval()\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toO0Ug5fz04f",
        "outputId": "8ed8fd0f-82f7-4f03-b474-43f34ebe3e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc, preds, labels = eval(model, testloader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7mobVGj1xFN",
        "outputId": "dc8e8f17-f741-4be3-d52b-9b71f1f0e129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 85.25345611572266%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "metadata": {
        "id": "22FqEG2sU2m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(preds, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ObOkwXEVU_6",
        "outputId": "c424f097-66d4-4d82-c93a-191d5485f076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8525345622119815"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(preds, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS4XbCf1VX2U",
        "outputId": "dd5ab614-a79a-451e-aab6-2c58439f401d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[112,  26],\n",
              "       [ 38, 258]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
>>>>>>> 4110f4f6fb28c0de2385ce5817827727ccc9f01b
    }
   ]
  }
 ]
}